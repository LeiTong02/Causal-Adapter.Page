<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Hello world - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="Lei Tong, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>PAPER_TITLE - AUTHOR_NAMES | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown -->
  

  <main id="main-content">
  <section class="hero hero-top">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title" style="color: #e3812c!important;">Taming Text-to-Image Diffusion for
 Counterfactual Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://leitong02.github.io/" target="_blank" >Lei Tong</a><sup>* 1</sup>,</span>
                <span class="author-block">
                  <a href="https://zhihualiued.github.io/" target="_blank">Zhihua Liu</a><sup>* 2</sup>,</span>
                  <span class="author-block">
                  <a href="https://causallu.com/" target="_blank">Chaochao Lu</a><sup>3</sup>,</span>
                  <span class="author-block">
                  <a href="https://doglic.bitbucket.io/" target="_blank">Dino Oglic</a><sup>1</sup>,</span>
                  <span class="author-block">
                  <a href="https://tomdiethe.com/" target="_blank">Tom Diethe</a><sup>1</sup>,</span>
                  <span class="author-block">
                  <a href="https://uk.linkedin.com/in/philteare" target="_blank">Philip Teare</a><sup>1</sup>,</span>
                  <span class="author-block">
                  <a href="https://eng.ed.ac.uk/about/people/professor-sotirios-tsaftaris" target="_blank">Sotirios A. Tsaftaris</a><sup>2</sup>,</span>
                  <span class="author-block">
                  <a href="https://chenjin.netlify.app/" target="_blank">Chen Jin</a><sup>1</sup>,</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    <span><sup>1</sup>&nbsp;AstraZeneca</span>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                    <span><sup>2</sup>&nbsp;University of Edinburgh</span>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                    <span><sup>3</sup>&nbsp;Shanghai AI Lab</span>
                    <br>
                    <span class="is-size-6">Preprint</span>
                  </span>

                  <span class="eql-cntrb">
                    <small><br><sup>*</sup>&nbsp;Indicates Equal Contribution</small>
                  </span>
                </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2509.24798.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2509.24798" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
        
      </div>
    </div>
  </div>
  
</section>

<!-- Teaser video-->
<section class="hero teaser teaser-compact" >
  <div class="container is-max-desktop">
    <div class="hero-body">

      <div class="teaser-wrap">
        <img
          src="static/images/fig1_ctf_illustration.png"
          alt="Learning from model weights"
          class="blend-img-background teaser-float-img"
          loading="lazy"
        />

        <p class="is-size-5">
        Counterfactual generation is specified by two standard inputs: a <strong>predefined causal graph</strong> and <strong>semantic attributes</strong> that define the intervention.
        <strong>Causal-Adapter</strong> instantiates an SCM over the conditioning variables and tames an off-the-shelf text-to-image diffusion backbone to disentangle causal factors in the text-embedding space, generating faithful counterfactual images.
        It can integrates seamlessly with Stable Diffusion 1.5/3, FLUX etc., with lightweight adaptation.
      </p>


        <div style="clear: both;"></div>
      </div>

    </div>
  </div>
</section>


<section class="hero teaser" style="background-color:#efeff081;">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Title and tagline, remains centered -->
        <h4 class="subtitle has-text-centered" style="font-size:1.1rem;">
          <strong>Taming T2I Diffusion for Counterfactual Generation</strong> <br />
          <em>“An off-the-shelf text-to-image diffusion model can be tamed with causal semantic attributes to generate faithful counterfactual images”</em>
        </h4>
        <!-- Centered Abstract Container with fixed max width -->
        <div class="abstract-summary" style="max-width: 1920px; margin: 0 auto; text-align: center;">
          <!-- <h2>Abstract</h2> -->
          <p>
            Causal-Adapter augments an SCM with prompt-aligned injection and a conditioned token contrastive loss to disentangle attributes, reduce spurious correlations, and achieve SOTA on synthetic and real-world datasets.
          </p>
          <p>
            <strong>Key highlights:</strong>
          </p>
  
          <!-- Bullet points also centered -->
          <ul style="list-style-position: inside;">
            <li><strong>Significant Gains:</strong> +50% intervention effectiveness; +87% image quality</li>
            <li><strong>Low Compute:</strong> Finetunes in 10 hours on 1 NVIDIA A10G (24GB).</li>
            <li><strong>Model-Agnostic:</strong> Works with Stable Diffusion 1.5, FLUX.1, and more.</li>
            <li><strong>Precise Attention:</strong> Better semantic–spatial alignment in diffusion latents.</li>
            <li><strong>Causal Graph Support:</strong> Supports learning causal structure (graph) from scratch.</li>
            <li><strong>Open-Source:</strong> Code, data & finetuned models will be available.</li>
          </ul>
  
          <!-- Expand/Collapse Toggle Button -->
          <button onclick="toggleAbstract()" style="margin-top:10px;">
            Read Abstract
          </button>
  
          <!-- Hidden Full Abstract -->
          <div id="full-abstract" style="display: none; margin-top:10px;">
            <p>
              We present Causal-Adapter, a modular framework that adapts frozen text-to-image diffusion for counterfactual generation. Our method enables causal interventions on target attributes, consistently propagating their effects to causal dependents without altering the core identity of the image. In contrast to prior approaches that rely on prompt engineering without explicit causal mechanism, Causal-Adapter leverages structural causal modeling augmented with two attribute regularization strategies: prompt-aligned injection, which aligns causal attributes with textual embeddings for precise semantic control, and a conditioned token contrastive loss to disentangle attribute factors and reduce spurious correlations. Causal-Adapter achieves state-of-the-art performance on both synthetic and real-world datasets, with up to 91% MAE reduction on Pendulum for accurate attribute control and 87% FID reduction on ADNI for high-fidelity MRI generation. These results show that our approach enables robust, generalizable counterfactual editing with faithful attribute modification and strong identity preservation.
            </p>
          </div>
        </div><!-- end of abstract-summary -->
      </div><!-- end of hero-body -->
    </div><!-- end of container -->
  </section>

  <script>
    function toggleAbstract() {
      const fullAbs = document.getElementById('full-abstract');
      if (fullAbs.style.display === 'none') {
        fullAbs.style.display = 'block';
      } else {
        fullAbs.style.display = 'none';
      }
    }
  </script>
  
  <script>
    function toggleAbstract() {
      const fullAbs = document.getElementById('full-abstract');
      if (fullAbs.style.display === 'none') {
        fullAbs.style.display = 'block';
      } else {
        fullAbs.style.display = 'none';
      }
    }
  </script>

<!-- End paper abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Key Insights and Figures</h2>
        </div>
      </div>

      <!-- Row of figures -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-justified">

              <div style="
              display: flex; 
              flex-wrap: wrap; 
              justify-content: center; 
              align-items: center; 
              gap: 20px;">

              <!-- First Figure -->
              <figure style="
                flex: 1 1 600px; 
                max-width: 100%; 
                min-width: 250px; 
                margin: 0; 
                text-align: center;">
                <img src="static/images/motivation_study.png" 
                     alt="Causal-Adapter Fig" 
                     style="width: 100%; vertical-align: middle;">
                <figcaption>
                  <small>
                    <em>Figure 1. Motivational study: (a) Current T2I models often overlook continuous attributes, limiting fine-grained edits. (b) Existing T2I methods suffer from attribute entanglement. (c) Cross-attention maps: base vs. regularized Causal-Adapter.
                  </small>
                </figcaption>
              </figure>
              
              
            </div>
            

            <div style="
              display: flex; 
              flex-wrap: wrap; 
              justify-content: center; 
              align-items: center; 
              gap: 20px;">
              
              <!-- First Figure -->
              <figure style="
                flex: 1 1 600px; 
                max-width: 100%; 
                min-width: 250px; 
                margin: 0; 
                text-align: center;">
                <img src="static/images/sketch_comparison.png" 
                     alt="Causal-Adapter Fig" 
                     style="width: 100%; vertical-align: middle;">
                <figcaption>
                  <small>
                    <em>Figure 2. A sketch comparison of counterfactual image generation methods based on: (a) VAE or GAN (b) Diffusion SCM and (c) Diffusion autoencoder (d) T2I based editing (e) Vanilla Causal-Adapter (f) Causal-Adapter with attribute regularization
                  </small>
                </figcaption>
              </figure>


          </div>
        </div>
      </div>

    </div>
  </section>


    <!-- ===== Additional / Detailed Methods Section ===== -->
  <section class="section" id="method" style="background-color:#efeff081">
    <div class="container is-max-desktop content">
      <h2 class="title is-3">Method</h2>

      <!-- Code snippet or pseudo-code from your LaTeX -->
      <div class="card mb-3">
        <div class="card-body" style="display:flex; flex-wrap:wrap; align-items:center; justify-content:space-between;">
          <div style="flex:1; min-width:300px; margin-right:1rem;">
            <img src="static/images/framework.png" alt="fig 3" style="max-width:100%;">
          </div>
        </div>
      </div>

      <p>
        We propose <strong>Causal-Adapter</strong>, a simple yet module that plugs into a pretrained text-to-image diffusion model to generate faithful counterfactual images. 
        Given an input image and an intervention specified by a causal graph and semantic attributes, Causal-Adapter injects causal signals into the text conditioning (via <strong>prompt-aligned injection</strong>) 
        and is trained with reconstruction and <strong>contrastive objectives</strong> to disentangle attributes and reduce spurious correlations. 
        At inference, intervened attributes update the conditioning to produce counterfactuals, 
        with optional attention guidance for localized edits while preserving non-intervened identity cues.
      </p>
    </div>
  </section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{tong2025causal,
  title={Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation},
  author={Tong, Lei and Liu, Zhihua and Lu, Chaochao and Oglic, Dino and Diethe, Tom and Teare, Philip and Tsaftaris, Sotirios A and Jin, Chen},
  journal={arXiv preprint arXiv:2509.24798},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!-- ===== Footer Section (Optional) ===== -->
  <footer class="footer has-text-centered" style="padding:2rem 10.5rem;">
    <div class="content">
      <p>
        <strong>Causal-Adapter</strong> by <a href="https://leitong02.github.io/" target="_blank">Lei Tong</a> @ <a href="https://github.com/AstraZeneca" target="_blank">
            Centre for AI, Data Science & Artificial Intelligence, BioPharmaceuticals R&D, AstraZeneca, Cambridge, UK</a>.
        </p>
        <p>
        Built upon open-source code from the broader academic community.
      </p>
    </div>
  </footer>


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
